{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer, TrainingArguments, Trainer, T5ForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import PIL\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import regex\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "elco_df = pd.read_csv('../../data/ELCo.csv')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmojisDataset(Dataset):\n",
    "    def __init__(self, elco_df, tokenizer):\n",
    "        super().__init__()\n",
    "        self.elco_df = elco_df\n",
    "        self.emoji_descriptions = [self.preprocess_emoji_description(desc) for desc in elco_df[\"Description\"]]\n",
    "        self.raw_emoji_descriptions = elco_df[\"Description\"].values\n",
    "        self.en = [self.preprocess_en(en) for en in elco_df[\"EN\"].values]\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def preprocess_emoji_description(self, text):\n",
    "        text = text.replace('\\'\\'', '').lower()\n",
    "        split_text = regex.findall(r'\\':?(.*?):?\\'', text)\n",
    "        return split_text\n",
    "    def preprocess_en(self, text):\n",
    "        return text.lower().strip()\n",
    "    \n",
    "    def preprocess_prompt(self, prompt):\n",
    "        inputs = self.tokenizer(prompt[\"prompt\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "        targets = self.tokenizer(prompt[\"target\"], truncation=True, padding=\"max_length\", max_length=4)\n",
    "        inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "        return inputs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.emoji_descriptions)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        emoji_description = \" \".join(self.emoji_descriptions[index])\n",
    "        prompt = f\"emoji group is [{emoji_description}], overall meaning is {self.en[index]}. Select from composition types: [Direct, Metaphorical, Semantic list, Reduplication, Single]. The composition type is:\"\n",
    "        target = self.elco_df[\"Composition strategy\"].values[index]\n",
    "        prompt_dict ={\n",
    "            \"prompt\": prompt,     \n",
    "            \"target\": target\n",
    "            }\n",
    "        inputs = self.preprocess_prompt(prompt_dict)\n",
    "        inputs[\"text\"] = prompt\n",
    "        inputs[\"target\"] = target\n",
    "        return inputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\CS4248\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yyxxc\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "train_df, validate_df = train_test_split(elco_df, test_size=0.2, random_state=42, stratify=elco_df[\"Composition strategy\"])\n",
    "train_dataset = EmojisDataset(elco_df=train_df, tokenizer=tokenizer)\n",
    "validate_datset = EmojisDataset(elco_df=validate_df, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‚ñÅ',\n",
       " 'e',\n",
       " 'm',\n",
       " 'oji',\n",
       " '‚ñÅgroup',\n",
       " '‚ñÅis',\n",
       " '‚ñÅ[',\n",
       " 'cross',\n",
       " '_',\n",
       " 'mark',\n",
       " '‚ñÅsix',\n",
       " '-',\n",
       " 't',\n",
       " 'hir',\n",
       " 't',\n",
       " 'y',\n",
       " '],',\n",
       " '‚ñÅoverall',\n",
       " '‚ñÅmeaning',\n",
       " '‚ñÅis',\n",
       " '‚ñÅwrong',\n",
       " '‚ñÅtime',\n",
       " '.',\n",
       " '‚ñÅSelect',\n",
       " '‚ñÅfrom',\n",
       " '‚ñÅcomposition',\n",
       " '‚ñÅtypes',\n",
       " ':',\n",
       " '‚ñÅ[',\n",
       " 'Direct',\n",
       " ',',\n",
       " '‚ñÅMeta',\n",
       " 'phor',\n",
       " 'ical',\n",
       " ',',\n",
       " '‚ñÅSe',\n",
       " 'man',\n",
       " 'tic',\n",
       " '‚ñÅlist',\n",
       " ',',\n",
       " '‚ñÅRed',\n",
       " 'u',\n",
       " 'plication',\n",
       " ',',\n",
       " '‚ñÅSingle',\n",
       " '].',\n",
       " '‚ñÅThe',\n",
       " '‚ñÅcomposition',\n",
       " '‚ñÅtype',\n",
       " '‚ñÅis',\n",
       " ':',\n",
       " '</s>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(validate_datset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\CS4248\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./emoji_composition_model\",\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validate_datset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='498' max='498' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [498/498 06:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.579800</td>\n",
       "      <td>0.401191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500800</td>\n",
       "      <td>0.347852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.484200</td>\n",
       "      <td>0.332514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=498, training_loss=0.9454755744780882, metrics={'train_runtime': 409.9758, 'train_samples_per_second': 9.688, 'train_steps_per_second': 1.215, 'total_flos': 67197204430848.0, 'train_loss': 0.9454755744780882, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_dataset = EmojisDataset(elco_df=elco_df, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1655/1655 [01:46<00:00, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5099697885196375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(model, tokenizer, input_text):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=5)\n",
    "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return prediction\n",
    "\n",
    "correct_predictions = 0\n",
    "for i in tqdm(range(len(overall_dataset)), total=len(overall_dataset)):\n",
    "    input_text = overall_dataset[i][\"text\"]\n",
    "    target = overall_dataset[i][\"target\"]\n",
    "    prediction = predict(model, tokenizer, input_text)\n",
    "\n",
    "    # print(f\"Input: {input_text}\")\n",
    "    # print(f\"Target: {target}\")\n",
    "    # print(f\"Prediction: {prediction}\")\n",
    "    # print(\"Correct prediction\")\n",
    "    if prediction == target:\n",
    "        correct_predictions += 1\n",
    "print(f\"Accuracy: {correct_predictions / len(overall_dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
